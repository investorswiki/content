---
keywords: Investing,Fundamental Analysis
title: Winsorized Mean
description: Winsorized mean is an averaging method that includes supplanting the littlest and biggest values of a data set with the perceptions closest to them.
---

# Winsorized Mean
## What Is the Winsorized Mean?

Winsorized mean is a method of averaging that initially replaces the littlest and biggest values with the perceptions closest to them. This is finished to limit the effect of exceptions or abnormal extreme values, or anomalies, on the calculation.

In the wake of supplanting the values, the [arithmetic mean](/arithmeticmean) formula is then used to compute the winsorized mean.

## Formula for the Winsorized Mean
<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>Winsorized Mean </mtext><mo>=</mo><mtext> </mtext><mfrac><mrow><msub><mi>x</mi><mi>n</mi></msub><mo>…</mo><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow></msub><mtext> </mtext><mo>+</mo><mtext> </mtext><msub><mi>x</mi><mrow><mi>n</mi><mo>+</mo><mn>2</mn></mrow></msub><mo>…</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><mi>N</mi></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext mathvariant="bold">where:</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtable rowspacing="0.24999999999999992em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>n</mi><mtext> </mtext><mo>=</mo><mtext> </mtext></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>The number of largest and smallest data</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>points to be replaced by the observation</mtext></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mtext>closest to them</mtext></mrow></mstyle></mtd></mtr></mtable></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mi>N</mi><mtext> </mtext><mo>=</mo><mtext> Total number of data points</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned} &amp;\text{Winsorized Mean}\ =\ \frac{x_{n}\dots x_{n+1}\ +\ x_{n+2}\dots x_{n}}{N}\\ &amp;\textbf{where:}\\ &amp;\begin{aligned} n\ =\ &amp;\text{The number of largest and smallest data}\\ &amp;\text{points to be replaced by the observation}\\ &amp;\text{closest to them}\end{aligned}\\ &amp;N\ =\ \text{Total number of data points} \end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:10.046330000000001em;vertical-align:-4.7731650000000005em;"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.2731650000000005em;"><span style="top:-8.512835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"></span></span><span style="top:-6.686835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"></span></span><span style="top:-3.526835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"></span></span><span style="top:-0.3868349999999996em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.7731650000000005em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:5.2731650000000005em;"><span style="top:-8.512835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">Winsorized Mean</span></span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.26033em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mbin mtight">+</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner">…</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-6.686835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord textbf">where:</span></span></span></span><span style="top:-3.526835em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"><span class="mord"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5000000000000004em;"><span style="top:-4.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">n</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace"> </span></span></span><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span><span style="top:-1.6599999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.000000000000001em;"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:2.5000000000000004em;"><span style="top:-4.66em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">The number of largest and smallest data</span></span></span></span><span style="top:-3.16em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">points to be replaced by the observation</span></span></span></span><span style="top:-1.6599999999999993em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord"></span><span class="mord text"><span class="mord">closest to them</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.000000000000001em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-0.3868349999999996em;"><span class="pstrut" style="height:4.5em;"></span><span class="mord"><span class="mord"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace"> </span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord text"><span class="mord">Total number of data points</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:4.7731650000000005em;"><span></span></span></span></span></span></span></span></span></span></span>
Winsorized means are communicated in two ways. A "k^n^" winsorized mean alludes to the replacement of the "k" littlest and biggest perceptions, where "k" is an integer. An "X%" winsorized mean includes supplanting a given percentage of values from the two closures of the data.

> The winsorized mean is accomplished by supplanting the littlest and biggest data points, then, at that point, summing every one of the data points and partitioning the sum by the total number of data points.
>
## What Does the Winsorized Mean Tell You?

The winsorized mean is less sensitive to anomalies since it can supplant them with less extreme values. That is, it is less powerless to anomalies versus the arithmetic average. Be that as it may, assuming a distribution has fat tails, the effect of eliminating the highest and least values in the distribution will have little influence as a result of the high degree of variability in the [distribution](/distribution) figures.

One major downside for winsorized means is that they normally bring some bias into the data set. By decreasing the influence of exceptions, the analysis is modified for better analysis, yet in addition eliminates data about the underlying data.

## Illustration of How to Use Winsorized Mean

How about we ascertain the winsorized mean for the accompanying data set: 1, 5, 7, 8, 9, 10, 34. In this model, we assume the winsorized mean is in the principal order, in which we supplant the littlest and biggest values with their nearest perceptions.

The data set presently shows up as follows: 5, 5, 7, 8, 9, 10, 10. Taking an arithmetic average of the new set delivers a winsorized mean of 7.7, or (5 + 5 + 7 + 8 + 9 + 10 + 10) isolated by 7. Note that the arithmetic mean would have been higher — 10.6. The winsorized mean effectively decreases the influence of the 34 value as an exception.

Or on the other hand consider a 20% winsorized mean that takes the top 10% and base 10% and replaces them with their next closest value. We will winsorize the accompanying data set: 2, 4, 7, 8, 11, 14, 18, 23, 23, 27, 35, 40, 49, 50, 55, 60, 61, 61, 62, 75. The two littlest and two biggest data points — 20% of the 20 data points — will be supplanted with their next closest value. Subsequently, the new data set is as per the following: 7, 7, 7, 8, 11, 14, 18, 23, 23, 27, 35, 40, 49, 50, 55, 60, 61, 61, 61, 61. The winsorized mean is 33.9, or the total of the data (678) partitioned by the total number of data points (20).

## Winsorized Mean versus Trimmed Mean

The winsorized mean incorporates changing data points, while the [trimmed mean](/trimmed_mean) includes eliminating data points. It is common for the winsorized mean and trimmed mean to be close or some of the time equivalent in value to one another.

## Highlights
- The winsorized mean isn't equivalent to the trimmed mean, which includes eliminating data points rather than supplanting them — albeit the consequences of the two will generally be close.
- It mitigates the effects of anomalies by supplanting them with less extreme values.
- The winsorized mean is an averaging method that includes supplanting the littlest and biggest values of a data set with the perceptions closest to them.
